% !TeX spellcheck = en_US
\chapter{Deep reinforcement learning}
In this chapter we will put \ac{DRL} into the context of broader field of artificial intelligence and explain how it differs from other approaches that attempt to imbue agents with some form of intelligence. Afterwards we will proceed to introduce the main algorithms that are relevant for the use in environments with continuous action spaces.  
\section{DRL in the context of AI}
\todo[inline]{
Aside from the attempts at creating more-or-less autonomous systems that can be traced to the earliest civilizations the history of modern AI started to be written by early pioneers in the 1950s and 1960s. The term itself is said to be first coined by John McCarthy, who along with many other influential figures met in 1956 at the now famous Dartmouth College conference \cite{dartmouth}, where the belief that machines could posses something akin to intelligence was solidified. The advances in \ac{AI} that soon followed were made possible by the improvements in computational power and more focused research efforts. However at this time most works still relied on techniques such as symbol manipulation and trial-and-error search. These early systems could play checkers and simple puzzle games, prove mathematical theorems (Geometry Theorem Prover), carry out simple written commands (SHRDLU) and even control a robot (Shakey) \cite{AI_modern}. But while these approaches were promising when applied to smaller well-defined scenarios, one thing they all had in common was their inability to scale well to larger, more realistic situations. In the context of reinforcement learning an important development that happened at this time was early work on neural networks that showed, among other things, that ca perceptron (perceptron = an individual virtual neuron capable of classifying data on its inputs) }



