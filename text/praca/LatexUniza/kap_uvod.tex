% !TeX spellcheck = en_US
\chapter{Introduction}


In the last couple of decades we have witnessed many groundbreaking developments that would have previously been reserved for science fiction. Modern mobile robots can walk, interact with objects and humans, even independently accomplish simple tasks previously only reserved for humans. However while the robots are becoming more complex by the year, so does the complexity of their design and development. This is most obvious with robots that utilize legs for the purposes of locomotion, which forces engineers to develop complex controllers that allow such machines to move about. Design of these controllers is more often than not non-trivial and as such it is often reserved for experienced control engineers. Still, even with a lot of effort success is not guaranteed and even well-designed robots rarely achieve the same grace of movement that animals are capable of.

With this paragraph we have formulated the problem that this thesis addresses. For one way of solving it we can, as engineers often do, draw inspiration from nature. An animal learns to walk, not by performing a deep analysis of its tendons and muscles and then committing months to study of books on control theory. No, an animal learns in a much more straightforward way by simply making attempts and attempting to achieve 'good results'. We write good results in quotation marks as measuring goodness of something can be in practice a difficult and often very subjective task. Regardless, this simple concept of making attempts and obtaining a measure of success is, not only present in nature, it is also at the core of one of the most promising sub-fields of artificial intelligence known as reinforcement learning (\ac{RL}). 

\newpage

In this text we will focus on:
\begin{enumerate}[leftmargin=2cm]
\item \textbf{Introducing deep reinforcement learning \ac{DRL}} techniques: with \ac{RL} maturing as a field a slew of different approaches at utilizing it become available. We will explore some of the most promising ones that are relevant for our use. 
\item \textbf{Simulation and modeling of a robot, task and reward}: just having a technique that works is not enough, so this chapter will be dedicated to constructing a simulated environment within which we will train a virtual robot to walk.
\item \textbf{Implementing the \ac{DRL}}: \todo[inline]{When I know more about the implementation details I need to modify this} 
\item \textbf{Training and results analysis}: this chapter will be dedicated to putting everything together and analyzing the obtained results.
\item \textbf{Transitioning into the real world}: \todo[inline]{See the comment above}
\end{enumerate}

